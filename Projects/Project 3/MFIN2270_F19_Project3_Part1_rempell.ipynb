{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3 - Part 1\n",
    "\n",
    "<b>This is an individual assignment. Project 3 - Part 2 will be a group assignment.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project 3 Part 1 submission for Leonid (rempell)\n"
     ]
    }
   ],
   "source": [
    "name = \"Leonid\"              # Enter your name\n",
    "user = \"rempell\"              # Enter your BC username\n",
    "print(\"Project 3 Part 1 submission for {} ({})\".format(name,user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please rename the file so that it includes your BC username. I would submit <b>MFIN2270_F19_Project3_Part1-reuterj</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>(5 points) Question 1.</b> This question is asking you to extend code from \"Project3_daily.ipynb\" to two additional assets. The ultimate goal will be to supplement the daily factor returns and daily returns for Bitcoin. Ethereum, and gold with daily returns for two stocks. You will use these stocks to answer questions below and in HW11. You may also end up using one or both of these stocks in Project 3 Part 2.\n",
    "\n",
    "I would like for you to download “Historical Data” on daily adjusted closing prices for two U.S. stocks from finance.yahoo.com. Your stock choices are constrained in three ways. First, each stock must be listed on NASDAQ or NYSE. Second, each stock must have traded continuously between September 2015 and October 2019. This rules out all recent IPOs. Third, you may not choose Apple (NASDAQ: AAPL).\n",
    "\n",
    "Once you find a potential stock, click on the “Historical Data” tab, set the date range to “Sep 01, 2015 - Nov 15, 2019” and click “Download Data.” “AAPL.csv” should appear in your “Downloads” folder. You need to read these data into Python.\n",
    "\n",
    "If you open “AAPL.csv” in a text editor (instead of Excel) you will see that the three lines of the downloaded data for Apple look like this:\n",
    "\n",
    "<i>Date,Open,High,Low,Close,Adj Close,Volume<br>\n",
    "2015-09-01,110.150002,111.879997,107.360001,107.720001,100.232323,76845900<br>\n",
    "2015-09-02,110.230003,112.339996,109.129997,112.339996,104.531181,61888800<br>\n",
    "2015-09-03,112.489998,112.779999,110.040001,110.370003,102.698120,53233900<br></i>\n",
    "\n",
    "Next, you want to create a list containing the date and the closing price, like so:\n",
    "\n",
    "<i>20150901,100.232323<br>\n",
    "20150902,104.531181<br>\n",
    "20150903,102.698120<br></i>\n",
    "\n",
    "This involves reformatting the date string and retaining only the adjusted closing prices. Create a list that replaces closing prices with daily returns. For AAPL, the new list will look something like this:\n",
    "\n",
    "<i>20150901,-99<br>\n",
    "20150902,0.042888939<br>\n",
    "20150903,-0.017536021<br></i>\n",
    "\n",
    "where I added -99 in 20150901 because there is no prior day’s adjusted closing price. \n",
    "\n",
    "Restrict dates to those with daily factor returns between October 1, 2015 and September 30, 2019 (as we did in Project3_daily.ipynb). (You may want to import the array of date strings created in \"Project3_daily.ipynb\" and use these strings to limit the set of dates.) \n",
    "\n",
    "Convert your list into two arrays, one containing dates and one containing daily returns based on changes in adjusted closing prices. Replace ‘-99’ with np.nan and count the number of np.nan that appear in your array of daily returns. It should be zero or very, very close to zero.\n",
    "\n",
    "For AAPL, the two arrays should be named “aapl_daily” and “aapl_dates”. Repeat this process for a second stock. Verify that the arrays of dates are identical for the two stocks. I would save “aapl_daily.npy”, “aapl_dates.npy”, and the corresponding arrays for my second stock, which has ticker AAP.\n",
    "\n",
    "Note: I include my versions of 'aapl_daily.npy' and 'aapl_dates.npy' on the assignment page for Project3. They can only be opened using <b>np.load()</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Date,Open,High,Low,Close,Adj Close,Volume\\n', '2015-09-01,137.580002,139.899994,137.500000,138.300003,126.957054,2968200\\n', '2015-09-02,139.830002,140.869995,138.419998,140.419998,128.903168,1809900\\n', '2015-09-03,140.940002,141.699997,140.100006,140.479996,128.958267,1615600\\n', '2015-09-04,138.800003,139.460007,138.179993,138.479996,127.122276,2124500\\n'] 2019-11-15,305.309998,305.440002,301.600006,303.660004,303.660004,1706100\n",
      "\n",
      "['Date,Open,High,Low,Close,Adj Close,Volume\\n', '2015-09-01,64.389999,65.739998,63.029999,63.430000,63.430000,5043700\\n', '2015-09-02,64.430000,65.120003,63.970001,64.669998,64.669998,3804900\\n', '2015-09-03,65.290001,66.500000,65.029999,65.790001,65.790001,3482300\\n', '2015-09-04,64.839996,66.580002,64.440002,66.370003,66.370003,3601000\\n'] 2019-11-15,98.849998,99.389999,97.370003,97.540001,97.540001,3315500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "costco = \"CostcoStock.csv\" \n",
    "ea = \"EA.csv\"\n",
    "\n",
    "c = open(costco, 'r')\n",
    "c_list = c.readlines()\n",
    "c.close()\n",
    "\n",
    "ea = open(ea, 'r')\n",
    "ea_list = ea.readlines()\n",
    "ea.close()\n",
    "\n",
    "print(c_list[0:5], c_list[-1])\n",
    "print(ea_list[0:5], ea_list[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['2015-09-01', '137.580002', '139.899994', '137.500000', '138.300003', '126.957054', '2968200'], ['2015-09-02', '139.830002', '140.869995', '138.419998', '140.419998', '128.903168', '1809900'], ['2015-09-03', '140.940002', '141.699997', '140.100006', '140.479996', '128.958267', '1615600'], ['2015-09-04', '138.800003', '139.460007', '138.179993', '138.479996', '127.122276', '2124500'], ['2015-09-08', '140.539993', '141.479996', '139.119995', '141.429993', '129.830338', '1638000']]\n",
      "[['2015-09-01', '64.389999', '65.739998', '63.029999', '63.430000', '63.430000', '5043700'], ['2015-09-02', '64.430000', '65.120003', '63.970001', '64.669998', '64.669998', '3804900'], ['2015-09-03', '65.290001', '66.500000', '65.029999', '65.790001', '65.790001', '3482300'], ['2015-09-04', '64.839996', '66.580002', '64.440002', '66.370003', '66.370003', '3601000'], ['2015-09-08', '67.550003', '68.610001', '67.000000', '68.500000', '68.500000', '3205700']]\n"
     ]
    }
   ],
   "source": [
    "ret_headers = ['Date', 'Adj Close']\n",
    "\n",
    "c_list = [element.rstrip().split(',') for element in c_list][1:]\n",
    "ea_list = [element.rstrip().split(',') for element in ea_list][1:]\n",
    "\n",
    "print(c_list[0:5])\n",
    "print(ea_list[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dates from print statement above are the same, I will be testing array dates later as well\n",
    "c_list = [((element[0].replace('-','')), float(element[5])) for element in c_list]\n",
    "ea_list = [((element[0].replace('-','')), float(element[5])) for element in ea_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('20150901', 126.957054), ('20150902', 128.903168), ('20150903', 128.958267), ('20150904', 127.122276), ('20150908', 129.830338)]\n",
      "[('20150901', 63.43), ('20150902', 64.669998), ('20150903', 65.790001), ('20150904', 66.370003), ('20150908', 68.5)]\n",
      "1061\n",
      "[('20150901', -99), ('20150901', 0.015328915871031431), ('20150902', 0.00042744488638178906), ('20150903', -0.014237094237626556), ('20150904', 0.021302812419752556)] ('20191114', -0.0030532585187071286)\n",
      "[('20150901', -99), ('20150901', 0.019549077723474806), ('20150902', 0.017318741837598278), ('20150903', 0.008815959738319402), ('20150904', 0.03209276636615495)] ('20191114', 0.0)\n"
     ]
    }
   ],
   "source": [
    "print(c_list[0:5])\n",
    "print(ea_list[0:5])\n",
    "\n",
    "c_rets = [('20150901', -99)]\n",
    "ea_rets = [('20150901', -99)]\n",
    "\n",
    "for i in range(len(c_list)):\n",
    "    try:\n",
    "        r = (c_list[i+1][1]-c_list[i][1])/c_list[i][1]\n",
    "        if r == -99:\n",
    "            r = np.nan\n",
    "        c_rets.append((c_list[i][0],r))\n",
    "        \n",
    "        r2 = (ea_list[i+1][1]-ea_list[i][1])/ea_list[i][1]\n",
    "        if r2 == -99:\n",
    "            r2 = np.nan\n",
    "        ea_rets.append((ea_list[i][0],r2))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print(len(c_rets))\n",
    "print(c_rets[0:5], c_rets[-1])\n",
    "print(ea_rets[0:5], ea_rets[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "['20151001' '20151002' '20151005' ... '20190926' '20190927' '20190930'] ['20151001' '20151002' '20151005' ... '20190926' '20190927' '20190930'] [ 0.00899266  0.01515167  0.00229591 ... -0.0080136   0.00755372\n",
      " -0.01450832] [-0.01056546  0.01654381 -0.01538679 ... -0.00983238  0.02247311\n",
      " -0.01093846]\n"
     ]
    }
   ],
   "source": [
    "begin = 0\n",
    "end = 0 \n",
    "\n",
    "for i in range(len(c_rets)):\n",
    "    if c_rets[i][0] == '20151001':\n",
    "        begin = i\n",
    "    if c_rets[i][0] == '20190930':\n",
    "        end = i\n",
    "        \n",
    "sc_rets = []\n",
    "sea_rets = []\n",
    "\n",
    "while begin <= end: \n",
    "    sc_rets.append(c_rets[begin])\n",
    "    sea_rets.append(ea_rets[begin])\n",
    "    begin = begin+1\n",
    "\n",
    "dates = [element[0] for element in sc_rets]\n",
    "d = np.array(dates)\n",
    "\n",
    "dates1 = [element[0] for element in sea_rets]\n",
    "d1 = np.array(dates1)\n",
    "\n",
    "c_rets = [element[1] for element in sc_rets]\n",
    "ea_rets = [element[1] for element in sea_rets]\n",
    "\n",
    "c = np.array(c_rets)\n",
    "e = np.array(ea_rets)\n",
    "\n",
    "print(np.array_equal(d,d1))\n",
    "print(d,d1,c,e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(c[c==np.nan])\n",
    "print(e[e==np.nan])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('dates_cost.npy', d)\n",
    "np.save('dates_ea.npy', d1)\n",
    "np.save('cost.npy', c)\n",
    "np.save('ea.npy', e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>(2 points) Question 2.</b> Create and print a “table” with a separate column for each stock that contains the average daily return, standard deviation of daily returns, as well as daily return percentiles 0, 10, 25, 50, 75, 90, and 100. The ticker of each stock should appear at the top of the column for that stock. Please format the summary statistics so that 1.0\\% appears as 1.0000\\% instead of 0.01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tAvg Daily\tStd.Dev Daily\t\n",
      "Costco\t 0.08%\t\t   1.21%\n",
      "EA\t 0.06%\t\t   2.01%\n",
      "\n",
      "Costco Percentiles:\n",
      "0th percentile is: -8.59%\n",
      "10th percentile is: -1.24%\n",
      "25th percentile is: -0.49%\n",
      "50th percentile is: 0.16%\n",
      "75th percentile is: 0.69%\n",
      "90th percentile is: 1.43%\n",
      "100th percentile is: 5.09%\n",
      "\n",
      "EA Percentiles:\n",
      "0th percentile is -13.31%\n",
      "10th percentile is -2.01%\n",
      "25th percentile is -0.90%\n",
      "50th percentile is 0.04%\n",
      "75th percentile is 1.03%\n",
      "90th percentile is 2.09%\n",
      "100th percentile is 16.05%\n"
     ]
    }
   ],
   "source": [
    "print('\\tAvg Daily\\tStd.Dev Daily\\t')\n",
    "print('Costco\\t {:.2f}%\\t\\t   {:.2f}%'.format(np.mean(c)*100, np.std(c)*100))\n",
    "print('EA\\t {:.2f}%\\t\\t   {:.2f}%\\n'.format(np.mean(e)*100, np.std(e)*100))\n",
    "\n",
    "print('Costco Percentiles:')\n",
    "for x in (0,10,25,50,75,90,100):\n",
    "    print(str(x)+'th percentile is: {:.2f}%'.format(np.percentile(c,x)*100))\n",
    "\n",
    "print('\\nEA Percentiles:')\n",
    "for x in (0,10,25,50,75,90,100):\n",
    "    print(str(x)+'th percentile is {:.2f}%'.format(np.percentile(e,x)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>(3 points) Question 3.</b> Create and print a \"table\" that reports correlations in the daily returns of the two stocks. The table should report an overall correlation using all daily return data as well as correlations using daily return data from only 2015, only 2016, only 2017, only 2018, and only 2019. I suggest a table with two columns. Column one describes the time period being summarized and column two contains the corresponding correlation coefficient calculated using data from that time period.\n",
    "\n",
    "Reminder: The first 4 characters of the date string '20170303' correspond to the year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tYear\tCorrCoeff\n",
      "\t 2015\t  0.27\n",
      "\t 2016\t  0.22\n",
      "\t 2017\t  -0.01\n",
      "\t 2018\t  0.31\n",
      "\t 2019\t  0.19\n",
      "\n",
      "The overall correlation coefficient is: 0.20\n"
     ]
    }
   ],
   "source": [
    "ov = np.corrcoef(e,c)\n",
    "o = ov[0][1]\n",
    "\n",
    "print('\\tYear\\tCorrCoeff')\n",
    "y = 0\n",
    "for x in range(len(d)):\n",
    "    if x+1!=len(d):\n",
    "        if d[x][0:4] != d[x+1][0:4]:\n",
    "            print('\\t {}\\t  {:.2f}'.format(d[x][0:4],np.corrcoef(e[y:x],c[y:x])[0,1]))\n",
    "            y = x\n",
    "    else:\n",
    "        print('\\t {}\\t  {:.2f}'.format(d[x][0:4],np.corrcoef(e[y:x],c[y:x])[0,1]))\n",
    "        \n",
    "print('\\nThe overall correlation coefficient is: {:.2f}'.format(o))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note: To submit Project 3 Part 1, I would upload five files to Canvas: this notebook, “aapl_daily.npy”, “aapl_dates.npy”, and the two corresponding arrays for my second stock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
