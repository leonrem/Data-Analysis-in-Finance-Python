{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3 Part 1 Solutions\n",
    "\n",
    "<b>This is an individual assignment. Project 3 - Part 2 will be a group assignment.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project 3 Part 1 submission for ABC (ABC)\n"
     ]
    }
   ],
   "source": [
    "name = \"ABC\"              # Enter your name\n",
    "user = \"ABC\"              # Enter your BC username\n",
    "print(\"Project 3 Part 1 submission for {} ({})\".format(name,user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please rename the file so that it includes your BC username. I would submit <b>MFIN2270_F19_Project3_Part1-reuterj</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>(5 points) Question 1.</b> This question is asking you to extend code from \"Project3_daily.ipynb\" to two additional assets. The ultimate goal will be to supplement the daily factor returns and daily returns for Bitcoin. Ethereum, and gold with daily returns for two stocks. You will use these stocks to answer questions below and in HW11. You may also end up using one or both of these stocks in Project 3 Part 2.\n",
    "\n",
    "I would like for you to download “Historical Data” on daily adjusted closing prices for two U.S. stocks from finance.yahoo.com. Your stock choices are constrained in three ways. First, each stock must be listed on NASDAQ or NYSE. Second, each stock must have traded continuously between September 2015 and October 2019. This rules out all recent IPOs. Third, you may not choose Apple (NASDAQ: AAPL).\n",
    "\n",
    "Once you find a potential stock, click on the “Historical Data” tab, set the date range to “Sep 01, 2015 - Nov 15, 2019” and click “Download Data.” “AAPL.csv” should appear in your “Downloads” folder. You need to read these data into Python.\n",
    "\n",
    "If you open “AAPL.csv” in a text editor (instead of Excel) you will see that the three lines of the downloaded data for Apple look like this:\n",
    "\n",
    "<i>Date,Open,High,Low,Close,Adj Close,Volume<br>\n",
    "2015-09-01,110.150002,111.879997,107.360001,107.720001,100.232323,76845900<br>\n",
    "2015-09-02,110.230003,112.339996,109.129997,112.339996,104.531181,61888800<br>\n",
    "2015-09-03,112.489998,112.779999,110.040001,110.370003,102.698120,53233900<br></i>\n",
    "\n",
    "Next, you want to create a list containing the date and the closing price, like so:\n",
    "\n",
    "<i>20150901,100.232323<br>\n",
    "20150902,104.531181<br>\n",
    "20150903,102.698120<br></i>\n",
    "\n",
    "This involves reformatting the date string and retaining only the adjusted closing prices. Create a list that replaces closing prices with daily returns. For AAPL, the new list will look something like this:\n",
    "\n",
    "<i>20150901,-99<br>\n",
    "20150902,0.042888939<br>\n",
    "20150903,-0.017536021<br></i>\n",
    "\n",
    "where I added -99 in 20150901 because there is no prior day’s adjusted closing price. \n",
    "\n",
    "Restrict dates to those with daily factor returns between October 1, 2015 and September 30, 2019 (as we did in Project3_daily.ipynb). (You may want to import the array of date strings created in \"Project3_daily.ipynb\" and use these strings to limit the set of dates.) \n",
    "\n",
    "Convert your list into two arrays, one containing dates and one containing daily returns based on changes in adjusted closing prices. Replace ‘-99’ with np.nan and count the number of np.nan that appear in your array of daily returns. It should be zero or very, very close to zero.\n",
    "\n",
    "For AAPL, the two arrays should be named “aapl_daily” and “aapl_dates”. Repeat this process for a second stock. Verify that the arrays of dates are identical for the two stocks. I would save “aapl_daily.npy”, “aapl_dates.npy”, and the corresponding arrays for my second stock, which has ticker AAP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading list of dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_dates = np.load('Project3_ret_rows.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('20151001', '20190930')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ff_dates[0], ff_dates[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing AAPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "aapl = open('Project3_AAPL.csv', 'r')\n",
    "aapl_list = aapl.readlines()\n",
    "aapl.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2015-09-01,110.150002,111.879997,107.360001,107.720001,100.232323,76845900\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aapl_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2015-09-01', '110.150002', '111.879997', '107.360001', '107.720001', '100.232323', '76845900']\n"
     ]
    }
   ],
   "source": [
    "aapl1 = [element.rstrip().split(',') for element in aapl_list][1:]\n",
    "print(aapl1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['20150901', 100.232323]\n"
     ]
    }
   ],
   "source": [
    "aapl2 = [[tup[0].replace('-',''), float(tup[5])] for tup in aapl1]\n",
    "print(aapl2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['20150901', -99]\n"
     ]
    }
   ],
   "source": [
    "aapl3 = [[aapl2[0][0], -99]]\n",
    "print(aapl3[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num in range(1,len(aapl2)):\n",
    "    aapl3.append([aapl2[num][0], (aapl2[num][1] / aapl2[num-1][1] - 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['20150901', -99], ['20150902', 0.04288893912994518], ['20150903', -0.017536021141863922]]\n",
      "[['20191030', -0.00012329643793140832], ['20191031', 0.022609550510779286], ['20191101', 0.028380816430090716]]\n"
     ]
    }
   ],
   "source": [
    "print(aapl3[0:3])\n",
    "print(aapl3[-3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "aapl4 = [tup for tup in aapl3 if tup[0] in ff_dates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['20151001', -0.006527725255141226], ['20151002', 0.0073006064668375], ['20151005', 0.0036239637896491317]]\n",
      "[['20190926', -0.005157640732988411], ['20190927', -0.004866027381099203], ['20190930', 0.023535243669489336]]\n"
     ]
    }
   ],
   "source": [
    "print(aapl4[0:3])\n",
    "print(aapl4[-3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "aapl_dates = np.array([tup[0] for tup in aapl4])\n",
    "aapl_daily = np.array([tup[1] for tup in aapl4])\n",
    "\n",
    "np.save(\"aapl_daily.npy\", aapl_daily)\n",
    "np.save(\"aapl_dates.npy\", aapl_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing AAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "aap = open('Project3_AAP.csv', 'r')\n",
    "aap_list = aap.readlines()\n",
    "aap.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "aap1 = [element.rstrip().split(',') for element in aap_list][1:]\n",
    "aap2 = [[tup[0].replace('-',''), float(tup[5])] for tup in aap1]\n",
    "\n",
    "aap3 = [[aap2[0][0], -99]]\n",
    "for num in range(1,len(aap2)):\n",
    "    aap3.append([aap2[num][0], (aap2[num][1] / aap2[num-1][1] - 1)])\n",
    "    \n",
    "aap4 = [tup for tup in aap3 if tup[0] in ff_dates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['20151001', 0.013243330806113507], ['20151002', -0.0018226002907949512], ['20151005', -0.002712486481572962]]\n",
      "[['20190926', -0.01170812183699843], ['20190927', 0.008105673771490407], ['20190930', 0.023008418858603052]]\n"
     ]
    }
   ],
   "source": [
    "print(aap4[0:3])\n",
    "print(aap4[-3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "aap_dates = np.array([tup[0] for tup in aap4])\n",
    "aap_daily = np.array([tup[1] for tup in aap4])\n",
    "\n",
    "np.save(\"aap_daily.npy\", aap_daily)\n",
    "np.save(\"aap_dates.npy\", aap_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1006,) (1006,)\n",
      "(1006,) (1006,)\n"
     ]
    }
   ],
   "source": [
    "print(aapl_dates.shape, aapl_daily.shape)\n",
    "print(aap_dates.shape, aap_daily.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>(2 points) Question 2.</b> Create and print a “table” with a separate column for each stock that contains the average daily return, standard deviation of daily returns, as well as daily return percentiles 0, 10, 25, 50, 75, 90, and 100. The ticker of each stock should appear at the top of the column for that stock. Please format the summary statistics so that 10.0\\% appears as 10.0\\% instead of 0.10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             AAPL         AAP\n",
      "         --------   ---------\n",
      " Mean:    0.0894%     0.0084%\n",
      "Stdev:    1.5539%     2.0508%\n",
      "  0th:   -9.9607%   -20.3439%\n",
      " 10th:   -1.6624%    -2.0022%\n",
      " 25th:   -0.5743%    -0.8251%\n",
      " 50th:    0.0715%     0.0244%\n",
      " 75th:    0.8718%     0.9318%\n",
      " 90th:    1.7046%     2.0100%\n",
      "100th:    7.0422%    16.3345%\n"
     ]
    }
   ],
   "source": [
    "print(\"             AAPL         AAP\")\n",
    "print(\"         --------   ---------\")\n",
    "print(\" Mean:  {:8.4f}%   {:8.4f}%\".format(100*np.mean(aapl_daily),100*np.mean(aap_daily)))\n",
    "print(\"Stdev:  {:8.4f}%   {:8.4f}%\".format(100*np.std(aapl_daily),100*np.std(aap_daily)))\n",
    "print(\"  0th:  {:8.4f}%   {:8.4f}%\".format(100*np.percentile(aapl_daily,0),100*np.percentile(aap_daily,0)))\n",
    "print(\" 10th:  {:8.4f}%   {:8.4f}%\".format(100*np.percentile(aapl_daily,10),100*np.percentile(aap_daily,10)))\n",
    "print(\" 25th:  {:8.4f}%   {:8.4f}%\".format(100*np.percentile(aapl_daily,25),100*np.percentile(aap_daily,25)))\n",
    "print(\" 50th:  {:8.4f}%   {:8.4f}%\".format(100*np.percentile(aapl_daily,50),100*np.percentile(aap_daily,50)))\n",
    "print(\" 75th:  {:8.4f}%   {:8.4f}%\".format(100*np.percentile(aapl_daily,75),100*np.percentile(aap_daily,75)))\n",
    "print(\" 90th:  {:8.4f}%   {:8.4f}%\".format(100*np.percentile(aapl_daily,90),100*np.percentile(aap_daily,90)))\n",
    "print(\"100th:  {:8.4f}%   {:8.4f}%\".format(100*np.percentile(aapl_daily,100),100*np.percentile(aap_daily,100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>(3 points) Question 3.</b> Create and print a \"table\" that reports correlations in the daily returns of the two stocks. The table should report an overall correlation using all daily return data as well as correlations using daily return data from only 2015, only 2016, only 2017, only 2018, and only 2019. I suggest a table with two columns. Column one describes the time period being summarized and column two contains the corresponding correlation coefficient calculated using data from that time period.\n",
    "\n",
    "Reminder: The first 4 characters of the date string '20170303' correspond to the year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = np.array([element[0:4] for element in ff_dates])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2015', '2016', '2017', '2018', '2019'] (1006,)\n"
     ]
    }
   ],
   "source": [
    "print(sorted(set(year)), year.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1006, 2)\n"
     ]
    }
   ],
   "source": [
    "stocks = np.hstack((aapl_daily.reshape(1006,1), aap_daily.reshape(1006,1)))\n",
    "print(stocks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-2019  0.1511\n",
      "2015       0.1951\n",
      "2016       0.2260\n",
      "2017      -0.1227\n",
      "2018       0.3087\n",
      "2019       0.1793\n"
     ]
    }
   ],
   "source": [
    "print(\"2015-2019 {:7.4f}\".format(np.corrcoef(stocks.T)[0,1]))\n",
    "for yyyy in sorted(set(year)):\n",
    "    print(\"{}      {:7.4f}\".format(yyyy, np.corrcoef(stocks[year==yyyy].T)[0,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note: To submit Project 3 Part 1, I would upload five files to Canvas: this notebook, “aapl_daily.npy”, “aapl_dates.npy”, and the two corresponding arrays for my second stock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
